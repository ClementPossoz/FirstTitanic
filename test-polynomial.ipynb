{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn as sk\n",
    "import csv\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv('../input/titanic/train.csv')\n",
    "test = pd.read_csv('../input/titanic/test.csv')\n",
    "\n",
    "#train.drop(columns=['Name','Ticket','Cabin'])  ---> Pourquoi ça ne marche pas ?\n",
    "#test.drop(columns=['Name','Ticket','Cabin'])\n",
    "\n",
    "#SUPRESSION DES DONNEES INUTILES\n",
    "Data.pop('Name')\n",
    "Data.pop('Ticket')\n",
    "Data.pop('Cabin')\n",
    "test.pop('Name')\n",
    "test.pop('Ticket')\n",
    "test.pop('Cabin')\n",
    "\n",
    "#Conversion des datas non-numériques\n",
    "\n",
    "Data['Sex'] = Data['Sex'].apply({'male':-1, 'female':1}.get)\n",
    "test['Sex'] = test['Sex'].apply({'male':-1, 'female':1}.get)\n",
    "Data['Embarked'] = Data['Embarked'].apply({'C':0, 'S':1, 'Q':0.5}.get)\n",
    "test['Embarked'] = test['Embarked'].apply({'C':0, 'S':1, 'Q':0.5}.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_interp(data):\n",
    "# GENERATION ET NORMALISATION DES DONNEES\n",
    "    dat = data.copy()\n",
    "    y=pd.DataFrame()\n",
    "    if 'Survived' in dat.columns:\n",
    "        y = dat['Survived'].copy()\n",
    "    Id = dat['PassengerId'].copy()\n",
    "    X=dat.drop(columns = ['Survived', 'PassengerId'])\n",
    "    \n",
    "    X_col=list(X.columns)\n",
    "    \n",
    "# NORMALISATION\n",
    "    X = 2*(X - X.mean()) / (X.max() - X.min())\n",
    "    \n",
    "# MODIFICATION : NAN->INTERPOLATION\n",
    "    if sum(X.isnull().values.ravel()) != 0:\n",
    "        from sklearn.experimental import enable_iterative_imputer\n",
    "        from sklearn.impute import IterativeImputer\n",
    "        imp = IterativeImputer(random_state=0)\n",
    "        X = imp.fit_transform(X)\n",
    "    \n",
    "    X=pd.DataFrame(X, columns=X_col)\n",
    "    \n",
    "    \n",
    "    return [X, Id, y] if 'Survived' in dat.columns else [X, Id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_mean(data):\n",
    "# GENERATION ET NORMALISATION DES DONNEES\n",
    "    dat = data.copy()\n",
    "    if 'Survived' in dat.columns:\n",
    "        y = dat['Survived'].copy()\n",
    "    Id = dat['PassengerId'].copy()\n",
    "    X=dat.drop(columns = ['Survived', 'PassengerId'])\n",
    "    \n",
    "# MODIFICATION : NAN->MEAN\n",
    "    colonnes_a_corriger = [col for col in dat.columns if dat[col].isnull().any()]\n",
    "    for col in colonnes_a_corriger:\n",
    "        colonnes = X[col].mean()\n",
    "        X[col]=X[col].fillna(colonnes)\n",
    "    \n",
    "# NORMALISATION\n",
    "    X = 2*(X - X.mean()) / (X.max() - X.min())\n",
    "    \n",
    "    return [X, Id, y] if 'Survived' in dat.columns else [X, Id]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_suppr(data):\n",
    "# GENERATION ET NORMALISATION DES DONNEES\n",
    "    dat = data.copy()\n",
    "    dat.dropna(inplace=True)\n",
    "    if 'Survived' in dat.columns:\n",
    "        y = dat['Survived'].copy()\n",
    "    Id = dat['PassengerId'].copy()\n",
    "    X=dat.drop(columns = ['Survived', 'PassengerId'])\n",
    "    \n",
    "# NORMALISATION\n",
    "    X = 2*(X - X.mean()) / (X.max() - X.min())\n",
    "    \n",
    "    return [X, Id, y] if 'Survived' in dat.columns else [X, Id]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS-VALIDATION SUR LE DEGRE\n",
    "def precision_poly(X_train_initial, y_train, X_cross_initial, y_cross, col_poly, algo, degre_max=10, nb_iter=10):\n",
    "    # ENTREES : X_train_initial et y_train : données et résultats du train set | X_cross_initial et y_cross: données et résultats du set de cross-validation | \n",
    "    #           col_fixes : colonnes des données qu'on veut à des degrés supérieurs | degre_max : exposant maximum du polynome des données |\n",
    "    #           nb_iter : nombre d'itérations pour le calcul moyen de la précision\n",
    "    #\n",
    "    #SORTIE : DataFrame contenant les colonnes : Degré (degré du polynome des données) (index)\n",
    "    #                                            Precision_train : précision moyenne sur le set de training\n",
    "    #                                            Precision_cross : précision moyenne sur le set de cross-vaisation\n",
    "    \n",
    "    train_prec = []\n",
    "    cross_prec = []\n",
    "    \n",
    "    for d in range(1,degre_max+1):\n",
    "        X_train = Polynomiation(X_train_initial, col_poly, d)\n",
    "        X_cross = Polynomiation(X_cross_initial, col_poly, d)       \n",
    "        [p_train, p_cross] = PrecisionMoyenne_train_cross(X_train, y_train, X_cross, y_cross, algo, nb_iter)\n",
    "        \n",
    "        train_prec.append(p_train)\n",
    "        cross_prec.append(p_cross)\n",
    "\n",
    "    prec_degre = pd.DataFrame({'Degre':list(range(1,degre_max+1)), 'Précision_Train':train_prec, 'Précision_Cross':cross_prec})\n",
    "    prec_degre.set_index('Degre', inplace=True) \n",
    "    \n",
    "    return prec_degre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrecisionMoyenne_train_cross(X_train_entree, y_train_entree, X_cross_entree, y_cross_entree, algo, nb_iter=10): \n",
    "#Renvoie la précision moyenne sur nb_iter itérations de l'algorithme sur les données de de train et de cross-validation \n",
    "#(si l'algorithme est déterministe, la précision est calculée seulement sur 1 iteration)  \n",
    "    \n",
    "    algorithme=algorithmes.loc[algo, 'Algorithme']\n",
    "    \n",
    "    X_train=X_train_entree.copy()\n",
    "    y_train=y_train_entree.copy()\n",
    "    X_cross=X_cross_entree.copy()\n",
    "    y_cros=y_cross_entree.copy()\n",
    "\n",
    "    prec_train = []\n",
    "    prec_cross = []\n",
    "    \n",
    "\n",
    "    for it in range(nb_iter):\n",
    "        algorithme.fit(X_train, y_train)\n",
    "        prediction_train = np.array(algorithme.predict(X_train))\n",
    "        precision_train = (prediction_train==y_train).mean()\n",
    "        prec_train.append(precision_train)\n",
    "        \n",
    "        prediction_cross = np.array(algorithme.predict(X_cross))\n",
    "        precision_cross = (prediction_cross==y_cross).mean()\n",
    "        prec_cross.append(precision_cross)\n",
    "        if prec_cross[it]==prec_cross[it-1]: break\n",
    "    \n",
    "    precision_moyenne_train = np.array(prec_train).mean()\n",
    "    precision_moyenne_cross = np.array(prec_cross).mean()\n",
    "    \n",
    "    return [precision_moyenne_train, precision_moyenne_cross]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION DES DONNEES POUR CROSS-VALIDATION ET TEST\n",
    "# Entrée : Données à séparer en groupe train / cross / test & Méthode de traitement des données manquante\n",
    "#Sortie : Dataframe contenant les données, l'identifiant et le résultat attendu pour chaque groupe Train, Cross et TestCross\n",
    "\n",
    "def preparation(data, methode):\n",
    "    ratio_TrainReste = 0.7\n",
    "    ratio_CrossTest = 0.5\n",
    "\n",
    "    [train, reste]=Split(data, ratio_TrainReste)\n",
    "    [cross, testcross]=Split(reste, ratio_CrossTest)\n",
    "    Train = [X_train_total, Id_train, y_train] = methode(train)\n",
    "    Cross = [X_cross_total, Id_cross, y_cross] = methode(cross)\n",
    "    TestCross= [X_testcross, Id_testcross, y_testcross] = methode(testcross)\n",
    "    \n",
    "    dat = pd.DataFrame({'Donnee':['X', 'Id', 'y'], 'Train':Train, 'Cross':Cross, 'TestCross':TestCross})\n",
    "    dat.set_index('Donnee', inplace=True)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " def Polynomiation(donnee, col_polynomes, deg):\n",
    "    col_fixes=set(donnee.columns.values.tolist())-set(col_polynomes)\n",
    "    donneePoly = donnee[col_fixes].copy()\n",
    "    donneePoly['Sex*Age']=donnee['Sex'].mul(donnee['Age'])\n",
    "    donneePoly['Sex*Embarked']=donnee['Sex'].mul(donnee['Embarked'])\n",
    "    donneePoly['Sex*Pclass']=donnee['Sex'].mul(donnee['Pclass'])\n",
    "\n",
    "    for degre in range(1,deg+1):\n",
    "        for col in col_polynomes :\n",
    "            donneePoly[col+'^'+str(degre)]=donnee[col].pow(degre)\n",
    "\n",
    "    return donneePoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SEPARATION POUR CROSS-VALIDATION -----\n",
    "def Split(donnee, ratio):\n",
    "\n",
    "    #SHUFFLE\n",
    "    donneesplit=donnee.sample(frac=1).copy()\n",
    "\n",
    "    # SEPARATION\n",
    "    part1 = donneesplit[:int(len(Data)*ratio)]\n",
    "    part2 = donneesplit[int(len(Data)*ratio):]\n",
    "    return [part1, part2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-0f07c7ee2074>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0f07c7ee2074>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for nom_algo in\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def Test_prediction(X_Train, y_Train, X_Test, precisions):\n",
    "    for nom_algo in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTE D'ALGORITHMES DE PREDICTION\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "Ridge = linear_model.RidgeClassifier()\n",
    "LinReg = linear_model.LogisticRegression()\n",
    "SDG = linear_model.SGDClassifier() #Stochastic Gradient Decent\n",
    "PassiveAgressive = linear_model.PassiveAggressiveClassifier()\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "Tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "Mlpc_R_L = MLPClassifier(activation = 'relu', solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = lbfgs, activation = relu\n",
    "Mlpc_R_S = MLPClassifier(activation = 'relu', solver='sgd', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = sgd, activation = relu\n",
    "Mlpc_R_A = MLPClassifier(activation = 'relu', solver='adam', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = adam, activation = relu\n",
    "Mlpc_T_L = MLPClassifier(activation = 'tanh', solver='lbfgs', max_iter=10000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = lbfgs, activation = tanh\n",
    "Mlpc_T_S = MLPClassifier(activation = 'tanh', solver='sgd', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = sgd, activation = tanh\n",
    "Mlpc_T_A = MLPClassifier(activation = 'tanh', solver='adam', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = adam, activation = tanh\n",
    "Mlpc_L_L = MLPClassifier(activation = 'logistic', solver='lbfgs', max_iter=10000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = lbfgs, activation = logistic\n",
    "Mlpc_L_S = MLPClassifier(activation = 'logistic', solver='sgd', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = sgd, activation = logistic\n",
    "Mlpc_L_A = MLPClassifier(activation = 'logistic', solver='adam', max_iter=1000, alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1) # Neural Network solver = adam, activation = logistic\n",
    "\n",
    "SVC = sk.svm.SVC()\n",
    "Kneighbors = sk.neighbors.KNeighborsClassifier()\n",
    "GaussProcess = GaussianProcessClassifier()\n",
    "GaussNB = GaussianNB()\n",
    "RandomForest = RandomForestClassifier()\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "nom_algo = ['Ridge', 'LinReg', 'SDG', 'PassiveAgressive', 'LDA', 'QDA', 'Tree', 'Mlpc_R_L', 'Mlpc_R_S', 'Mlpc_R_A', 'Mlpc_T_L', 'Mlpc_T_S', 'Mlpc_T_A', 'Mlpc_L_L', 'Mlpc_L_S', 'Mlpc_L_A', 'SVC', 'Kneighbors', 'GaussProcess', 'GaussNB', 'RandomForest', 'AdaBoost']\n",
    "liste_algos=[Ridge, LinReg, SDG, PassiveAgressive, LDA, QDA, Tree, Mlpc_R_L, Mlpc_R_S, Mlpc_R_A, Mlpc_T_L,Mlpc_T_S, Mlpc_T_A, Mlpc_L_L, Mlpc_L_S, Mlpc_L_A, SVC,Kneighbors, GaussProcess, GaussNB, RandomForest, AdaBoost]\n",
    "algorithmes = pd.DataFrame({'Nom':nom_algo, 'Algorithme':liste_algos})\n",
    "algorithmes.set_index('Nom', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# ------------ CROSS-VALIDATION : MOYENNE DES ALGORITHMES ------------ \n",
    "#Essai avec donnes_mean\n",
    "Methode = data_interp\n",
    "noms_algos = algorithmes.index\n",
    "degre_max=6\n",
    "nb_iter=10\n",
    "\n",
    "donnees_preparees = preparation(Data, Methode)\n",
    "[X_train_initial, Id_train, y_train] = donnees_preparees['Train']\n",
    "[X_cross_initial, Id_cross, y_cross] = donnees_preparees['Cross']\n",
    "[X_testcross, Id_testcross, y_testcross] = donnees_preparees['TestCross']\n",
    "\n",
    "col_poly=['Pclass', 'Age','SibSp', 'Parch', 'Fare']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for d in range(1,degre_max+1):\n",
    "    for i in range(len(nom_algo)):\n",
    "        algo = noms_algos[i]\n",
    "        prec = precision_poly(X_train_initial, y_train, X_cross_initial, y_cross, col_poly, algo, degre_max, nb_iter)\n",
    "        results[algo]=prec\n",
    "            \n",
    "precisions = pd.concat(results)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions.to_csv('precisions_moyennes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION MOYENNE \n",
    "#p_temp = np.array(predictions_cross.replace({0:-1})).dot(np.array(results['Précision : Cross']))\n",
    "#p_temp = p_temp[p_temp>0]=1\n",
    "#p_temp = p_temp[p_temp<0]=0\n",
    "#p_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas import DataFrame\n",
    "#tops_mean = DataFrame({'prediction moyenne':tops.mean()},columns=['prediction moyenne'])\n",
    "#tops_mean.loc[tops_mean['prediction moyenne']>0.5, 'prediction moyenne']=1\n",
    "#tops_mean.loc[tops_mean['prediction moyenne']<=0.5, 'prediction moyenne']=0\n",
    "#precision_topsmean = (np.array(tops_mean['prediction moyenne'])==np.array(y_cross)).mean()\n",
    "\n",
    "#precision_topsmean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
